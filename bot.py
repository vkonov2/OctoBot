import logging
import os
import PyPDF2
import pandas as pd
import docx
import mimetypes
import json
import re
from functools import wraps
from dotenv import load_dotenv
from telegram import (
    Update, InlineKeyboardButton, InlineKeyboardMarkup,
    BotCommand, BotCommandScopeDefault
)
from telegram.constants import ParseMode
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    filters, ContextTypes, CallbackQueryHandler
)
import aiohttp
import asyncio
import base64
from PIL import Image
from io import BytesIO

# –ê–∫—Ç–∏–≤–Ω—ã–µ file-—Å–µ—Å—Å–∏–∏: user_id -> dict —Å vector_store_id, assistant_id, thread_id, file_id, file_name
ACTIVE_FILE_SESSIONS = {}

for logger_name in [
    "httpx",
    "urllib3",
    "telegram",
    "apscheduler",
]:
    logging.getLogger(logger_name).setLevel(logging.WARNING)

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ---
load_dotenv()
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
PROXYAPI_KEY = os.getenv('PROXYAPI_KEY')
ALLOWED_USER_IDS = set(int(x) for x in os.getenv('ALLOWED_USER_IDS', '').split(',') if x)
ADMIN_USER_IDS = set(int(x) for x in os.getenv('ADMIN_USER_IDS', '').split(',') if x)

PROXYAPI_CHAT_ENDPOINT = "https://api.proxyapi.ru/openai/v1/chat/completions"
PROXYAPI_MODELS_ENDPOINT = "https://api.proxyapi.ru/openai/v1/models"
PROXYAPI_ASR_ENDPOINT = "https://api.proxyapi.ru/openai/v1/audio/transcriptions"

LOG_FORMAT = '[%(asctime)s] %(levelname)s:%(name)s:%(filename)s:%(lineno)d: %(message)s'
logging.basicConfig(
    level=logging.INFO,
    format=LOG_FORMAT,
    handlers=[
        logging.FileHandler("bot.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# --- –ò—Å—Ç–æ—Ä–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---
HISTORY_DIR = "history"
os.makedirs(HISTORY_DIR, exist_ok=True)
HISTORY_MAX_PAIRS = 40

def _history_path(user_id):
    return os.path.join(HISTORY_DIR, f"history_{user_id}.json")

def get_user_history(user_id):
    path = _history_path(user_id)
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                history = json.load(f)
            return history
        except Exception:
            return []
    return []

def add_to_history(user_id, role, content):
    path = _history_path(user_id)
    history = get_user_history(user_id)
    history.append({"role": role, "content": content})
    if len(history) > HISTORY_MAX_PAIRS * 2:
        history = history[-HISTORY_MAX_PAIRS*2:]
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ –≤ —Ñ–∞–π–ª: {e}")

def reset_history(user_id):
    path = _history_path(user_id)
    try:
        if os.path.exists(path):
            os.remove(path)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")

def collect_history_stats(min_messages=1):
    stats = []
    if not os.path.exists(HISTORY_DIR):
        return stats
    for filename in os.listdir(HISTORY_DIR):
        if filename.startswith("history_") and filename.endswith(".json"):
            try:
                user_id = filename[len("history_"):-len(".json")]
                with open(os.path.join(HISTORY_DIR, filename), "r", encoding="utf-8") as f:
                    history = json.load(f)
                msg_count = len(history)
                if msg_count >= min_messages:
                    stats.append((user_id, msg_count))
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ {filename}: {e}")
    stats.sort(key=lambda x: x[1], reverse=True)
    return stats

# --- –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ---
DEFAULT_MODEL_PATH = "default_model.txt"

def get_default_model():
    if os.path.exists(DEFAULT_MODEL_PATH):
        try:
            with open(DEFAULT_MODEL_PATH, "r", encoding="utf-8") as f:
                return f.read().strip()
        except Exception:
            pass
    return "gpt-4.1-mini"

def set_default_model(model):
    with open(DEFAULT_MODEL_PATH, "w", encoding="utf-8") as f:
        f.write(model.strip())

# --- –ú–æ–¥–µ–ª–∏ ---
RELEVANT_MODELS = [
    "gpt-4o", "gpt-4-vision-preview", "gpt-4.1-mini", "gpt-4.1", "gpt-4.1-2025-04-14",
    "gpt-4", "gpt-4-0613", "gpt-4-1106-preview", "gpt-4-0125-preview",
    "gpt-4-turbo", "gpt-4-turbo-2024-04-09", "gpt-4-turbo-preview",
    "gpt-3.5-turbo", "gpt-3.5-turbo-16k"
]
VISION_MODELS = ["gpt-4-vision-preview", "gpt-4o"]
TOP_MODELS_LIMIT = 10

MODEL_DESCRIPTIONS = {
    "gpt-4": "GPT-4 (—Ñ–ª–∞–≥–º–∞–Ω, —Å–∞–º—ã–π —Ç–æ—á–Ω—ã–π, –Ω–æ –¥–æ—Ä–æ–≥–æ–π; —Ö–æ—Ä–æ—à –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á)",
    "gpt-4-0125-preview": "GPT-4 January 2025 Preview (–æ–±–Ω–æ–≤–ª—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è GPT-4 —Å —É—Å–∫–æ—Ä–µ–Ω–∏—è–º–∏ –∏ –Ω–æ–≤—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏)",
    "gpt-4-0613": "GPT-4 June 2023 (—Å—Ç–∞—Ä—ã–π —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Ä–µ–ª–∏–∑; —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π, –±—ã—Å—Ç—Ä—ã–π)",
    "gpt-4-1106-preview": "GPT-4 Preview (–±—ã—Å—Ç—Ä—ã–π, –¥–µ—à–µ–≤–ª–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ GPT-4, —Å–≤–µ–∂–∏–µ —Ñ–∏—á–∏)",
    "gpt-4-turbo": "GPT-4 Turbo (—É—Å–∫–æ—Ä–µ–Ω–Ω–∞—è, –±–æ–ª–µ–µ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –≤–µ—Ä—Å–∏—è GPT-4, —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã—Ö –∑–∞–¥–∞—á)",
    "gpt-4-turbo-2024-04-09": "GPT-4 Turbo (–∞–ø—Ä–µ–ª—å—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ 2024, —É–ª—É—á—à–µ–Ω–∞ —Ä–∞–±–æ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º)",
    "gpt-4-turbo-preview": "GPT-4 Turbo Preview (–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è turbo, –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–æ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π)",
    "gpt-4.1": "GPT-4.1 (–º–æ–¥–µ—Ä–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π GPT-4, –µ—â—ë –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã–π –∏ —Ç–æ—á–Ω—ã–π, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–ª–∏–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º)",
    "gpt-4.1-2025-04-14": "GPT-4.1 (–∞–ø—Ä–µ–ª—å—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ 2025, –µ—â—ë –±–æ–ª–µ–µ —É–º–Ω–∞—è –≤–µ—Ä—Å–∏—è GPT-4.1)",
    "gpt-4.1-mini": "GPT-4.1 Mini (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è, –±—ã—Å—Ç—Ä–∞—è –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –≤–µ—Ä—Å–∏—è GPT-4.1, –æ—Ç–ª–∏—á–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤)",
    "gpt-4o": "GPT-4o (–º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è, –ø–æ–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç, —Ñ–æ—Ç–æ, —Å–∫—Ä–∏–Ω—à–æ—Ç—ã)",
    "gpt-4-vision-preview": "GPT-4 Vision (–º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è; –ø–æ–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç + –∫–∞—Ä—Ç–∏–Ω–∫–∏)",
    "gpt-3.5-turbo": "GPT-3.5 turbo (–±—ã—Å—Ç—Ä—ã–π –∏ –¥–µ—à–µ–≤—ã–π)",
    "gpt-3.5-turbo-16k": "GPT-3.5 turbo 16k (–±–æ–ª—å—à–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç)",
}

ADMIN_ONLY_MODELS = set()

available_models = []
user_models = {}

SYSTEM_PROMPT = {
    "role": "system",
    "content": (
        "–¢—ã Telegram-–±–æ—Ç. –í—Å–µ–≥–¥–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–π —Å–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã —Å –ø–æ–º–æ—â—å—é —Ä–∞–∑–º–µ—Ç–∫–∏ Telegram HTML: "
        "<b>–∂–∏—Ä–Ω—ã–π</b>, <i>–∫—É—Ä—Å–∏–≤</i>, <code>–∫–æ–¥</code>, <pre>–±–ª–æ–∫ –∫–æ–¥–∞</pre>. "
        "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π markdown! –î–ª—è –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω–æ–≥–æ –∫–æ–¥–∞ –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π <pre>...</pre>."
    )
}

async def fetch_available_models():
    headers = {"Authorization": f"Bearer {PROXYAPI_KEY}"}
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(PROXYAPI_MODELS_ENDPOINT, headers=headers, timeout=20) as resp:
                resp.raise_for_status()
                j = await resp.json()
                models = j.get("data", [])
                models = sorted(models, key=lambda m: (not m["id"].startswith("gpt-4"), m["id"]))
                return models
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        return []

async def reload_models():
    global available_models
    models = await fetch_available_models()
    if not models:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π.")
        return False
    available_models = models
    logger.info(f"–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –æ–±–Ω–æ–≤–ª–µ–Ω, –Ω–∞–π–¥–µ–Ω–æ: {len(available_models)}")
    return True

def get_user_model(user_id):
    default_model = get_default_model()
    for m in available_models:
        if m["id"] not in ADMIN_ONLY_MODELS or is_admin(user_id):
            return user_models.get(user_id, default_model if any(am["id"] == default_model for am in available_models) else m["id"])
    return user_models.get(user_id, default_model if any(am["id"] == default_model for am in available_models) else (available_models[0]["id"] if available_models else "gpt-4.1-mini"))

def set_user_model(user_id, model):
    user_models[user_id] = model

def is_allowed(user_id):
    return user_id in ALLOWED_USER_IDS or user_id in ADMIN_USER_IDS

def is_admin(user_id):
    return user_id in ADMIN_USER_IDS

def allowed_only(func):
    @wraps(func)
    async def wrapper(update, context, *args, **kwargs):
        user_id = update.effective_user.id
        if not is_allowed(user_id):
            if hasattr(update, "message") and update.message:
                await update.message.reply_text("–£ –≤–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ —ç—Ç–æ–º—É –±–æ—Ç—É.")
            elif hasattr(update, "callback_query") and update.callback_query:
                await update.callback_query.answer("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞!")
            logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –æ—Ç –Ω–µ—Ä–∞–∑—Ä–µ—à–µ–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_id}")
            return
        return await func(update, context, *args, **kwargs)
    return wrapper

def admin_only(func):
    @wraps(func)
    async def wrapper(update, context, *args, **kwargs):
        user_id = update.effective_user.id
        if not is_admin(user_id):
            if hasattr(update, "message") and update.message:
                await update.message.reply_text("–£ –≤–∞—Å –Ω–µ—Ç –∞–¥–º–∏–Ω—Å–∫–∏—Ö –ø—Ä–∞–≤.")
            elif hasattr(update, "callback_query") and update.callback_query:
                await update.callback_query.answer("–ù–µ—Ç –∞–¥–º–∏–Ω—Å–∫–∏—Ö –ø—Ä–∞–≤!")
            logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –∞–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_id}")
            return
        return await func(update, context, *args, **kwargs)
    return wrapper

# FSM –¥–ª—è —Ä–∞—Å—Å—ã–ª–∫–∏
BROADCAST_STATE_FILE = "broadcast_state.json"

def set_broadcast_wait(user_id):
    with open(BROADCAST_STATE_FILE, "w", encoding="utf-8") as f:
        json.dump({"user_id": user_id}, f)

def clear_broadcast_wait():
    if os.path.exists(BROADCAST_STATE_FILE):
        os.remove(BROADCAST_STATE_FILE)

def get_broadcast_wait():
    if not os.path.exists(BROADCAST_STATE_FILE):
        return None
    try:
        with open(BROADCAST_STATE_FILE, "r", encoding="utf-8") as f:
            obj = json.load(f)
        return obj.get("user_id")
    except Exception:
        return None

@admin_only
async def broadcast_text_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∂–¥–µ—Ç –ª–∏ –±–æ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è —Ä–∞—Å—Å—ã–ª–∫–∏ –∏–º–µ–Ω–Ω–æ –æ—Ç —ç—Ç–æ–≥–æ –∞–¥–º–∏–Ω–∞
    if get_broadcast_wait() == user_id:
        message = update.message.text
        clear_broadcast_wait()
        # –°–æ–±–∏—Ä–∞–µ–º id –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –∏—Å—Ç–æ—Ä–∏–µ–π (–º–æ–∂–Ω–æ –ø–æ –ª–æ–≥–∏–∫–µ —Å–≤–æ–µ–π –±–∞–∑—ã)
        all_user_ids = [int(filename[len("history_"):-len(".json")])
                        for filename in os.listdir(HISTORY_DIR)
                        if filename.startswith("history_") and filename.endswith(".json")]
        sent = 0
        for uid in all_user_ids:
            try:
                await context.bot.send_message(uid, message, parse_mode=ParseMode.HTML)
                sent += 1
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ {uid}: {e}")
        await update.message.reply_text(f"–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {sent} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º.", parse_mode=ParseMode.HTML)
        return True  # –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
    return False  # –Ω–µ –±—ã–ª–æ —Ä–∞—Å—Å—ã–ª–∫–∏, –æ–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞

async def notify_admins(application, text, only_first=True):
    for admin_id in ADMIN_USER_IDS:
        try:
            await application.bot.send_message(admin_id, text, parse_mode=ParseMode.HTML)
            if only_first:
                break
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É {admin_id}: {e}")

async def error_handler(update, context):
    import traceback
    tb = traceback.format_exception(None, context.error, context.error.__traceback__)
    error_text = f"‚ùóÔ∏è–û—à–∏–±–∫–∞:\n{''.join(tb)[-2000:]}"
    logger.error(error_text)
    app = context.application if hasattr(context, "application") else None
    if app:
        await notify_admins(app, f"*–û—à–∏–±–∫–∞ –≤ –±–æ—Ç–µ:*\n```{error_text}```", only_first=True)

def markdown_code_to_html(text):
    # –ë–ª–æ–∫–∏ –∫–æ–¥–∞
    text = re.sub(r'```(?:\w+)?\n(.*?)```', lambda m: f"<pre>{m.group(1)}</pre>", text, flags=re.DOTALL)
    text = re.sub(r'`([^`]+?)`', r'<code>\1</code>', text)
    text = text.replace("```", "")

    # –°–ø–∏—Å–∫–∏ Markdown –≤ ‚Ä¢
    text = re.sub(r"^\s*[-*]\s+", "‚Ä¢ ", text, flags=re.MULTILINE)
    # HTML —Å–ø–∏—Å–∫–∏ –≤ ‚Ä¢
    text = re.sub(r"<ul>|</ul>|<ol>|</ol>", "", text, flags=re.IGNORECASE)
    text = re.sub(r"<li>(.*?)</li>", r"‚Ä¢ \1\n", text, flags=re.IGNORECASE|re.DOTALL)
    # –£–±–∏—Ä–∞–µ–º unsupported —Ç–µ–≥–∏
    text = re.sub(r"</?(span|table|tr|td|th|hr|br)[^>]*>", "", text, flags=re.IGNORECASE)
    # –£–±–∏—Ä–∞–µ–º –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ç–µ–≥–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ—á–µ–Ω—å –Ω—É–∂–Ω–æ)
    # text = re.sub(r"</?[a-z][^>]*>", "", text)
    return text

async def download_and_encode_photo(bot, file_id, max_size=2 * 1024 * 1024):
    file = await bot.get_file(file_id)
    file_bytes = await file.download_as_bytearray()
    if len(file_bytes) > max_size:
        image = Image.open(BytesIO(file_bytes))
        scale = (max_size / len(file_bytes)) ** 0.5
        new_w = int(image.width * scale)
        new_h = int(image.height * scale)
        image = image.resize((max(new_w, 1), max(new_h, 1)))
        buf = BytesIO()
        image.save(buf, format="JPEG", quality=85)
        file_bytes = buf.getvalue()
    base64_data = base64.b64encode(file_bytes).decode()
    mime_type = "image/jpeg"
    return base64_data, mime_type

async def transcribe_voice(bot, voice_file_id):
    file = await bot.get_file(voice_file_id)
    voice_bytes = await file.download_as_bytearray()
    async with aiohttp.ClientSession() as session:
        data = aiohttp.FormData()
        data.add_field('file', voice_bytes, filename="voice.ogg", content_type='audio/ogg')
        data.add_field('model', 'whisper-1')
        headers = {"Authorization": f"Bearer {PROXYAPI_KEY}"}
        async with session.post(PROXYAPI_ASR_ENDPOINT, headers=headers, data=data) as resp:
            if resp.status != 200:
                text = await resp.text()
                logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {resp.status} {text}")
                raise Exception("–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏")
            j = await resp.json()
            return j.get("text", "")

async def ask_llm_stream_history_vision(history, model):
    vision_history = [SYSTEM_PROMPT] + history
    headers = {
        'Authorization': f'Bearer {PROXYAPI_KEY}',
        'Content-Type': 'application/json',
    }
    data = {
        "model": model,
        "messages": vision_history,
        "temperature": 0.7,
        "max_tokens": 1024,
        "stream": True,
    }
    async with aiohttp.ClientSession() as session:
        async with session.post(PROXYAPI_CHAT_ENDPOINT, headers=headers, json=data, timeout=120) as response:
            if response.status != 200:
                logger.error(f"–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {await response.text()}")
                response.raise_for_status()
            async for line in response.content:
                if line:
                    try:
                        line = line.decode()
                        if line.startswith('data:'):
                            json_data = line[len('data:'):].strip()
                            if json_data == '[DONE]':
                                break
                            delta = json.loads(json_data)
                            yield delta
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ vision-—Å—Ç—Ä–∏–º–∞: {e}")

@allowed_only
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    user_id = user.id
    photo = update.message.photo[-1]
    caption = update.message.caption or ""
    user_model = get_user_model(user_id)

    reply_ref = ""
    if update.message.reply_to_message:
        orig = update.message.reply_to_message
        reply_content = orig.text or orig.caption or "[–Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞]"
        if len(reply_content) > 500:
            reply_content = reply_content[:500] + "‚Ä¶"
        reply_ref = f'üí¨ –í –æ—Ç–≤–µ—Ç –Ω–∞:\n"{reply_content}"\n\n'

    prompt = (reply_ref + caption.strip()) if caption or reply_ref else "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."

    if any(user_model.startswith(m) for m in VISION_MODELS):
        vision_model = user_model
    else:
        vision_model = next((m["id"] for m in available_models if m["id"] in VISION_MODELS), None)
        if not vision_model:
            await update.message.reply_text(
                "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏—Ö –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (Vision)."
            )
            return

    base64_img, mime_type = await download_and_encode_photo(context.bot, photo.file_id)

    history = get_user_history(user_id)
    multimodal_content = []
    if prompt:
        multimodal_content.append({"type": "text", "text": prompt})
    multimodal_content.append({"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{base64_img}"}})
    history.append({"role": "user", "content": multimodal_content})
    add_to_history(user_id, "user", multimodal_content)

    msg = await update.message.reply_text("üñºÔ∏è –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    reply_text = ""
    last_sent = ""
    token_count = 0
    has_updated_once = False

    try:
        async for chunk in ask_llm_stream_history_vision(history, vision_model):
            if 'choices' in chunk and chunk['choices']:
                delta = chunk['choices'][0]['delta']
                content = delta.get('content', '')
                if content:
                    reply_text += content
                    token_count += 1
                    if (token_count % 8 == 0 or len(reply_text) - len(last_sent) > 30) or not has_updated_once:
                        try:
                            await msg.edit_text(reply_text + " ‚ñç")
                            last_sent = reply_text
                            has_updated_once = True
                        except Exception as e:
                            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ edit_text: {e}\n–û—Ç–≤–µ—Ç: {reply_text}")
        safe_text = markdown_code_to_html(reply_text)
        await msg.edit_text(safe_text, parse_mode=ParseMode.HTML)
        add_to_history(user_id, "assistant", reply_text)
        logger.info(f'[Vision] –ì–æ—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {reply_text[:100]}...')
    except Exception:
        await msg.edit_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")


@allowed_only
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    user_id = user.id
    voice = update.message.voice
    caption = update.message.caption or ""

    reply_ref = ""
    if update.message.reply_to_message:
        orig = update.message.reply_to_message
        reply_content = orig.text or orig.caption or "[–Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞]"
        if len(reply_content) > 500:
            reply_content = reply_content[:500] + "‚Ä¶"
        reply_ref = f'üí¨ –í –æ—Ç–≤–µ—Ç –Ω–∞:\n"{reply_content}"\n\n'

    msg = await update.message.reply_text("üîä –†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")

    try:
        asr_text = await transcribe_voice(context.bot, voice.file_id)
        prompt = ""
        if caption and asr_text:
            prompt = f"{reply_ref}{caption.strip()}\n\n{asr_text}"
        elif asr_text:
            prompt = reply_ref + asr_text
        elif caption:
            prompt = reply_ref + caption.strip()
        else:
            prompt = reply_ref
            if not prompt.strip():
                await msg.edit_text("–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –∏–∑ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.")
                return

        history = get_user_history(user_id)
        history.append({"role": "user", "content": prompt})
        add_to_history(user_id, "user", prompt)

        model = get_user_model(user_id)
        reply_text = ""
        last_sent = ""
        token_count = 0
        has_updated_once = False

        await msg.edit_text("‚úçÔ∏è –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")

        async for chunk in ask_llm_stream_history(history, model):
            if 'choices' in chunk and chunk['choices']:
                delta = chunk['choices'][0]['delta']
                content = delta.get('content', '')
                if content:
                    reply_text += content
                    token_count += 1
                    if (token_count % 8 == 0 or len(reply_text) - len(last_sent) > 30) or not has_updated_once:
                        try:
                            await msg.edit_text(reply_text + " ‚ñç")
                            last_sent = reply_text
                            has_updated_once = True
                        except Exception as e:
                            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ edit_text: {e}\n–û—Ç–≤–µ—Ç: {reply_text}")
        safe_text = markdown_code_to_html(reply_text)
        await msg.edit_text(safe_text, parse_mode=ParseMode.HTML)
        add_to_history(user_id, "assistant", reply_text)
        logger.info(f'[Voice] –ì–æ—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {reply_text[:100]}...')
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ: {e}")
        await msg.edit_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ/–æ—Ç–≤–µ—Ç–µ –Ω–∞ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")


async def ask_llm_stream_history(history, model):
    full_history = [SYSTEM_PROMPT] + history
    headers = {
        'Authorization': f'Bearer {PROXYAPI_KEY}',
        'Content-Type': 'application/json',
    }
    data = {
        "model": model,
        "messages": full_history,
        "temperature": 0.7,
        "max_tokens": 1024,
        "stream": True,
    }
    async with aiohttp.ClientSession() as session:
        async with session.post(PROXYAPI_CHAT_ENDPOINT, headers=headers, json=data, timeout=90) as response:
            if response.status != 200:
                logger.error(f"–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {await response.text()}")
                response.raise_for_status()
            async for line in response.content:
                if line:
                    try:
                        line = line.decode()
                        if line.startswith('data:'):
                            json_data = line[len('data:'):].strip()
                            if json_data == '[DONE]':
                                break
                            delta = json.loads(json_data)
                            yield delta
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∏–º–∞: {e}")

# --- –†–ê–°–®–ò–†–ï–ù–ù–û–ï –ü–†–ò–í–ï–¢–°–¢–í–ò–ï –∏ –°–ü–†–ê–í–ö–ê ---
WELCOME_DESCRIPTION = (
    "üëã <b>–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å!</b>\n"
    "–≠—Ç–æ—Ç Telegram-–±–æ—Ç ‚Äî –≤–∞—à –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ –±–∞–∑–µ —Å–∞–º—ã—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö LLM –º–æ–¥–µ–ª–µ–π (GPT-4, GPT-4o –∏ –¥—Ä.).\n\n"
    "–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\n"
    "‚Ä¢ <b>–î–∏–∞–ª–æ–≥–æ–≤—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç</b>: –æ—Ç–≤–µ—á–∞–µ–º –Ω–∞ –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã, —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è, –ø–µ—Ä–µ–≤–æ–¥, –∫—Ä–µ–∞—Ç–∏–≤, –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ, —É—á–µ–±–∞, —Å–æ–≤–µ—Ç—ã –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ!\n"
    "‚Ä¢ <b>–ö–∞—Ä—Ç–∏–Ω–∫–∏</b>: –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –∏–ª–∏ —Å–∫—Ä–∏–Ω—à–æ—Ç, –±–æ—Ç –ø–æ–π–º—ë—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–æ–ø–∏—à–µ—Ç, –æ—Ç–≤–µ—Ç–∏—Ç –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É, –ø–µ—Ä–µ–≤–µ–¥—ë—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏ —Ç.–¥.).\n"
    "‚Ä¢ <b>–ì–æ–ª–æ—Å–æ–≤—ã–µ</b>: –æ—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è ‚Äî –±–æ—Ç —Ä–∞—Å—à–∏—Ñ—Ä—É–µ—Ç –∏ –æ—Ç–≤–µ—Ç–∏—Ç –Ω–∞ –Ω–∏—Ö –∫–∞–∫ –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç.\n"
    "‚Ä¢ <b>–ë—ã—Å—Ç—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—è</b>: –ø–æ–¥ –∫–∞–∂–¥—ã–º –æ—Ç–≤–µ—Ç–æ–º –¥–æ—Å—Ç—É–ø–Ω—ã –∫–Ω–æ–ø–∫–∏ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è, –ø–µ—Ä–µ–≤–æ–¥–∞, —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏ –¥—Ä.\n"
    "‚Ä¢ <b>–†–µ–∞–∫—Ü–∏–∏</b>: –º–æ–∂–Ω–æ –±—ã—Å—Ç—Ä–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å —Ä–µ–∞–∫—Ü–∏—é-—ç–º–æ–¥–∑–∏ –Ω–∞ –æ—Ç–≤–µ—Ç.\n"
    "‚Ä¢ <b>–ò—Å—Ç–æ—Ä–∏—è</b>: –≤—Å—è –≤–∞—à–∞ –ø–µ—Ä–µ–ø–∏—Å–∫–∞ —Å –±–æ—Ç–æ–º —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è, –º–æ–∂–Ω–æ –≤—ã–≥—Ä—É–∑–∏—Ç—å –¥–∏–∞–ª–æ–≥ —Ç–µ–∫—Å—Ç–æ–º —á–µ—Ä–µ–∑ /export\n"
    "‚Ä¢ <b>–°–º–µ–Ω–∞ –º–æ–¥–µ–ª–∏</b>: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ (GPT-4, 4o, Vision –∏ –¥—Ä.)\n"
    "‚Ä¢ <b>–†–∞—Å—Å—ã–ª–∫–∞ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</b>: –∞–¥–º–∏–Ω—ã –º–æ–≥—É—Ç –≤–∏–¥–µ—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, —Ä–∞—Å—Å—ã–ª–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –≤—Å–µ–º.\n"
    "‚Ä¢ <b>–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–ø—Ä–∞–≤–∫–∞</b>: –≤—Å–µ –∫–æ–º–∞–Ω–¥—ã –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –º–µ–Ω—é (‚ò∞) –∏–ª–∏ —á–µ—Ä–µ–∑ /menu –∏ /help\n"
    "\n<b>–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –∏–ª–∏ –≥–æ–ª–æ—Å ‚Äî –∏ –ø–æ–ª—É—á–∏—Ç–µ –æ—Ç–≤–µ—Ç!</b>"
)

HELP_INTRO = (
    "<b>üõ† –°–ø—Ä–∞–≤–∫–∞ –ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º –±–æ—Ç–∞:</b>\n"
    "–≠—Ç–æ—Ç –±–æ—Ç ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö LLM. –î–æ—Å—Ç—É–ø–Ω—ã —Ç–µ–∫—Å—Ç, –≥–æ–ª–æ—Å, —Ñ–æ—Ç–æ, –±—ã—Å—Ç—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—è, —ç–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏, –º–µ–Ω—é –∏ –∞–¥–º–∏–Ω–∫–∞.\n\n"
    "üöÄ <b>–§–∏—à–∫–∏ –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:</b>\n"
    "‚Äî –í–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç, –¥–∏–∞–ª–æ–≥\n"
    "‚Äî –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (Vision)\n"
    "‚Äî –ì–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n"
    "‚Äî –ò—Å—Ç–æ—Ä–∏—è (–≤—ã–≥—Ä—É–∑–∫–∞ /export)\n"
    "‚Äî –†–µ–∞–∫—Ü–∏–∏ –∏ –±—ã—Å—Ç—Ä—ã–µ –∫–Ω–æ–ø–∫–∏\n"
    "‚Äî –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π /model\n"
    "‚Äî –ú–µ–Ω—é (‚ò∞) —Å –∫–æ–º–∞–Ω–¥–∞–º–∏\n"
    "‚Äî –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å –∏ —Ä–∞—Å—Å—ã–ª–∫–∞\n"
    "\n"
    "<b>–ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è?</b>\n"
    "1. –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ –∏–ª–∏ —Ñ–æ—Ç–æ.\n"
    "2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é (‚ò∞) –∏–ª–∏ /menu –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–∞–Ω–¥.\n"
    "3. –î–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –∏—Å—Ç–æ—Ä–∏–∏ ‚Äî –∫–æ–º–∞–Ω–¥–∞ /export\n"
    "4. –ë—ã—Å—Ç—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∏ —Ä–µ–∞–∫—Ü–∏–∏ ‚Äî —Å—Ä–∞–∑—É –ø–æ–¥ –æ—Ç–≤–µ—Ç–æ–º."
)

HELP_COMMANDS = [
    {"cmd": "/start", "desc": "–ó–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞. –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ —Å—Ç–∞—Ä—Ç —Ä–∞–±–æ—Ç—ã.", "admin": False},
    {"cmd": "/menu", "desc": "–ü–æ–∫–∞–∑–∞—Ç—å –º–µ–Ω—é –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–º–∞–Ω–¥.", "admin": False},
    {"cmd": "/draw", "desc": "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é", "admin": False},
    {"cmd": "/help", "desc": "–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ –±–æ—Ç—É.", "admin": False},
    {"cmd": "/model", "desc": "–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å LLM –¥–ª—è –æ—Ç–≤–µ—Ç–∞. –î–æ—Å—Ç—É–ø–Ω—ã —Ç–æ–ª—å–∫–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏.", "admin": False},
    {"cmd": "/reset", "desc": "–ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥, –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π.", "admin": False},
    {"cmd": "/export", "desc": "–í—ã–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ—é –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ —Å –±–æ—Ç–æ–º (–≤ –≤–∏–¥–µ txt-—Ñ–∞–π–ª–∞).", "admin": False},
    {"cmd": "/broadcast", "desc": "–ê–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥–∞: –º–∞—Å—Å–æ–≤–∞—è —Ä–∞—Å—Å—ã–ª–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤—Å–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º.", "admin": True},
    {"cmd": "/cancel", "desc": "–û—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º —Ä–∞—Å—Å—ã–ª–∫–∏ (–¥–ª—è –∞–¥–º–∏–Ω–æ–≤).", "admin": True},
    {"cmd": "/reloadmodels", "desc": "–û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö LLM –º–æ–¥–µ–ª–µ–π (–∞–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥–∞).", "admin": True},
    {"cmd": "/admin", "desc": "–û—Ç–∫—Ä—ã—Ç—å –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.", "admin": True},
    {"cmd": "/closefile", "desc": "–ó–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–±–æ—Ç—É —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º", "admin": False}
]

HELP_USAGE = (
    "\n\n<b>üìù –ü–æ–¥—Ä–æ–±–Ω–µ–µ:</b>\n"
    "‚Äî –ü—Ä–æ—Å—Ç–æ –ø–∏—à–∏—Ç–µ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ —Ñ–æ—Ç–æ/–≥–æ–ª–æ—Å–æ–≤–æ–µ ‚Äî –±–æ—Ç —Å–∞–º –≤—Å—ë –ø–æ–π–º—ë—Ç –∏ –æ—Ç–≤–µ—Ç–∏—Ç.\n"
    "‚Äî –ú–µ–Ω—é —Å–æ –≤—Å–µ–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ ‚Äî –∫–Ω–æ–ø–∫–∞ ‚ò∞ (—Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–µ–ø–∫–æ–π).\n"
    "‚Äî –ò—Å—Ç–æ—Ä–∏—è –≤–∞—à–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞ —Å –±–æ—Ç–æ–º —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –∏ –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ —á–µ—Ä–µ–∑ /export.\n"
    "‚Äî –ë—ã—Å—Ç—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∏ —Ä–µ–∞–∫—Ü–∏–∏ –ø–æ–¥ –∫–∞–∂–¥—ã–º –æ—Ç–≤–µ—Ç–æ–º –ø–æ–∑–≤–æ–ª—è—é—Ç —É–ø—Ä–æ—Å—Ç–∏—Ç—å —Ä–∞–±–æ—Ç—É.\n"
    "‚Äî –î–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤ –¥–æ—Å—Ç—É–ø–Ω—ã –∫–æ–º–∞–Ω–¥—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, —Ä–∞—Å—Å—ã–ª–æ–∫, –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.\n"
)

@allowed_only
async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    is_admin_user = (user_id in ADMIN_USER_IDS)
    text = HELP_INTRO + "\n\n<b>–ö–æ–º–∞–Ω–¥—ã:</b>\n"
    for cmd in HELP_COMMANDS:
        if cmd["admin"] and not is_admin_user:
            continue
        admin_tag = " <i>[–∞–¥–º–∏–Ω]</i>" if cmd["admin"] else ""
        text += f"{cmd['cmd']}: {cmd['desc']}{admin_tag}\n"
    text += HELP_USAGE
    await update.message.reply_text(text, parse_mode=ParseMode.HTML)

async def set_bot_commands(application):
    commands = [
        BotCommand("menu", "–ü–æ–∫–∞–∑–∞—Ç—å –º–µ–Ω—é –∫–æ–º–∞–Ω–¥"),
        BotCommand("draw", "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é"),
        BotCommand("help", "–°–ø—Ä–∞–≤–∫–∞ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"),
        BotCommand("model", "–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å LLM"),
        BotCommand("reloadmodels", "–û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π (–∞–¥–º–∏–Ω—ã)"),
        BotCommand("admin", "–ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å"),
        BotCommand("reset", "–ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ (–æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é)"),
        BotCommand("export", "–í—ã–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ (txt-—Ñ–∞–π–ª)"),
        BotCommand("broadcast", "–†–∞—Å—Å—ã–ª–∫–∞ –≤—Å–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º (–∞–¥–º–∏–Ω—ã)"),
        BotCommand("cancel", "–û—Ç–º–µ–Ω–∞ —Ä–µ–∂–∏–º–∞ —Ä–∞—Å—Å—ã–ª–∫–∏"),
        BotCommand("start", "–ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –±–æ—Ç–æ–º"),
    ]
    await application.bot.set_my_commands(commands, scope=BotCommandScopeDefault())

def get_last_logs(n=40):
    path = "bot.log"
    if not os.path.exists(path):
        return "–õ–æ–≥-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω."
    with open(path, "r", encoding="utf-8") as f:
        lines = f.readlines()
    return "".join(lines[-n:])[-4000:]

@admin_only
async def admin_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        [InlineKeyboardButton("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", callback_data="admin:stats")],
        [InlineKeyboardButton("üìù –ü–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏", callback_data="admin:logs")],
        [InlineKeyboardButton("‚öôÔ∏è –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é", callback_data="admin:defmodel")],
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    if hasattr(update, "message") and update.message:
        await update.message.reply_text("–ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å:", reply_markup=reply_markup, parse_mode=ParseMode.HTML)
    elif hasattr(update, "callback_query") and update.callback_query:
        await update.callback_query.edit_message_text("–ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å:", reply_markup=reply_markup, parse_mode=ParseMode.HTML)

@admin_only
async def admin_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    data = query.data
    if data == "admin:stats":
        stats = collect_history_stats(min_messages=1)
        if not stats:
            msg = "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö."
        else:
            msg = "–¢–æ–ø-10 –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π:\n"
            top = stats[:10]
            for i, (uid, msg_count) in enumerate(top, 1):
                msg += f"{i}) <code>{uid}</code>: —Å–æ–æ–±—â–µ–Ω–∏–π {msg_count}\n"
            if len(stats) > 10:
                msg += f"\n–í—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö: {len(stats)}. –î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤—Å–µ—Ö ‚Äî –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ."
        keyboard = []
        if len(stats) > 10:
            keyboard = [
                [InlineKeyboardButton("–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ—Ö", callback_data="admin:allusers")]
            ]
        await query.edit_message_text(msg, parse_mode=ParseMode.HTML, reply_markup=InlineKeyboardMarkup(keyboard) if keyboard else None)

    elif data == "admin:allusers":
        stats = collect_history_stats(min_messages=1)
        if not stats:
            msg = "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö."
        else:
            msg = "–í—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏:\n"
            for i, (uid, msg_count) in enumerate(stats, 1):
                msg += f"{i}) <code>{uid}</code>: —Å–æ–æ–±—â–µ–Ω–∏–π {msg_count}\n"
        await query.edit_message_text(msg, parse_mode=ParseMode.HTML)

    elif data == "admin:logs":
        logs = get_last_logs()
        await query.edit_message_text(
            f"<b>–ü–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏:</b>\n<pre>{logs}</pre>", parse_mode=ParseMode.HTML
        )
    elif data == "admin:defmodel":
        current = get_default_model()
        models = [m["id"] for m in available_models if m["id"] in MODEL_DESCRIPTIONS]
        keyboard = [
            [InlineKeyboardButton(f"{'‚úÖ ' if m == current else ''}{m}", callback_data=f"admin:setdefmodel:{m}")]
            for m in models
        ]
        await query.edit_message_text(
            f"–ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: <b>{current}</b>\n\n–í—ã–±–µ—Ä–∏ –Ω–æ–≤—É—é:", parse_mode=ParseMode.HTML,
            reply_markup=InlineKeyboardMarkup(keyboard)
        )
    elif data.startswith("admin:setdefmodel:"):
        new_model = data.split(":")[-1]
        set_default_model(new_model)
        await query.answer(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {new_model}")
        await admin_command(update, context)

@admin_only
async def broadcast_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    set_broadcast_wait(update.effective_user.id)
    await update.message.reply_text(
        "–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è —Ä–∞—Å—Å—ã–ª–∫–∏ –≤—Å–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º (–∏–ª–∏ /cancel –¥–ª—è –æ—Ç–º–µ–Ω—ã).", parse_mode=ParseMode.HTML
    )

@admin_only
async def cancel_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    waiting_admin = get_broadcast_wait()
    if waiting_admin == update.effective_user.id:
        clear_broadcast_wait()
        await update.message.reply_text("–†–µ–∂–∏–º —Ä–∞—Å—Å—ã–ª–∫–∏ –æ—Ç–º–µ–Ω—ë–Ω.", parse_mode=ParseMode.HTML)
    else:
        await update.message.reply_text("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ —Ä–∞—Å—Å—ã–ª–∫–∏.", parse_mode=ParseMode.HTML)

@allowed_only
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if not os.path.exists(_history_path(user_id)):
        text = WELCOME_DESCRIPTION
    else:
        text = (
            "–†–∞–¥—ã —Å–Ω–æ–≤–∞ –≤–∏–¥–µ—Ç—å –≤–∞—Å!\n"
            "–ì–æ—Ç–æ–≤—ã –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –¥–∏–∞–ª–æ–≥ –∏–ª–∏ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å.\n\n"
            "‚Äî –î–ª—è —Å–ø—Ä–∞–≤–∫–∏ –∏ –æ–ø–∏—Å–∞–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /help."
        )
    await update.message.reply_text(text, parse_mode=ParseMode.HTML)

@allowed_only
async def menu_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (
        "<b>–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–º–∞–Ω–¥:</b>\n"
        "/start ‚Äî –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –±–æ—Ç–æ–º\n"
        "/help ‚Äî —Å–ø—Ä–∞–≤–∫–∞ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è\n"
        "/menu ‚Äî —ç—Ç–æ –º–µ–Ω—é\n"
        "/draw ‚Äî —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é\n"
        "/model ‚Äî –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å LLM\n"
        "/reset ‚Äî –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ (–æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é)\n"
        "/export ‚Äî –≤—ã–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ (txt-—Ñ–∞–π–ª)\n"
        "/dochelp ‚Äî –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —Ä–∞–±–æ—Ç–µ —Å —Ñ–∞–π–ª–∞–º–∏\n"
        "/closefile ‚Äî –∑–∞–∫—Ä—ã—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç\n"
        "/reloadmodels ‚Äî –æ–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π (–∞–¥–º–∏–Ω—ã)\n"
        "/admin ‚Äî –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)\n"
        "/broadcast ‚Äî —Ä–∞—Å—Å—ã–ª–∫–∞ –≤—Å–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º (–∞–¥–º–∏–Ω—ã)\n"
        "/cancel ‚Äî –æ—Ç–º–µ–Ω–∏—Ç—å —Ä–∞—Å—Å—ã–ª–∫—É\n"
        "‚Äî –ú–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Ñ–æ—Ç–æ –∏ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è.\n"
        "‚Äî –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –ª—é–±–æ–π –≤–æ–ø—Ä–æ—Å!\n"
    )
    await update.message.reply_text(text, parse_mode=ParseMode.HTML)

@allowed_only
async def reset_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    reset_history(user_id)
    await update.message.reply_text("–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞. –ú–æ–∂–Ω–æ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä!", parse_mode=ParseMode.HTML)

@allowed_only
async def export_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    history = get_user_history(user_id)
    if not history:
        await update.message.reply_text("–£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π.", parse_mode=ParseMode.HTML)
        return

    lines = []
    for msg in history:
        role = "üßë‚Äçüíª –í—ã" if msg["role"] == "user" else "ü§ñ –ë–æ—Ç"
        content = msg["content"]
        if isinstance(content, list):
            line = role + ":\n"
            for part in content:
                if part["type"] == "text":
                    line += part["text"] + "\n"
                elif part["type"] == "image_url":
                    line += "[–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ]\n"
            lines.append(line)
        else:
            lines.append(f"{role}:\n{content}\n")

    export_text = "\n".join(lines)
    export_filename = f"chat_history_{user_id}.txt"
    with open(export_filename, "w", encoding="utf-8") as f:
        f.write(export_text)

    with open(export_filename, "rb") as f:
        await update.message.reply_document(
            f,
            filename=export_filename,
            caption="–í–∞—à–∞ –∏—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞"
        )

    try:
        os.remove(export_filename)
    except Exception:
        pass

@allowed_only
async def model_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    current = get_user_model(user_id)

    def is_relevant(m):
        return (
            m["id"] in RELEVANT_MODELS
            or m["id"].startswith("gpt-4.1")
            or m["id"].startswith("gpt-4")
            or m["id"].startswith("gpt-3.5-turbo")
        ) and not any(x in m["id"] for x in [
            "embedding", "tts", "dall-e", "whisper", "image", "moderation", "transcribe", "audio", "search", "codex", "babbage", "davinci"
        ])

    models_to_show = [
        m for m in available_models
        if is_relevant(m) and (m["id"] not in ADMIN_ONLY_MODELS or is_admin(user_id))
    ][:TOP_MODELS_LIMIT]

    if not models_to_show:
        await update.message.reply_text("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã–±–æ—Ä–∞.", parse_mode=ParseMode.HTML)
        return
    keyboard = [
        [InlineKeyboardButton(
            f"{'‚úÖ ' if m['id']==current else ''}{m['id']}",
            callback_data=f"set_model:{m['id']}")]
        for m in models_to_show
    ]
    text = "–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:\n"
    for m in models_to_show:
        desc = MODEL_DESCRIPTIONS.get(m["id"], "")
        text += f"‚Äî {m['id']}: {desc}\n"
    text += f"\n–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {current}"
    reply_markup = InlineKeyboardMarkup(keyboard)
    if hasattr(update, "message") and update.message:
        await update.message.reply_text(text, reply_markup=reply_markup, parse_mode=ParseMode.HTML)
    elif hasattr(update, "callback_query") and update.callback_query:
        await update.callback_query.edit_message_text(text, reply_markup=reply_markup, parse_mode=ParseMode.HTML)

@allowed_only
async def model_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    user_id = query.from_user.id
    data = query.data
    if data.startswith("set_model:"):
        model = data.split(":", 1)[1]
        def is_relevant(m):
            return (
                m["id"] in RELEVANT_MODELS
                or m["id"].startswith("gpt-4.1")
                or m["id"].startswith("gpt-4")
                or m["id"].startswith("gpt-3.5-turbo")
            ) and not any(x in m["id"] for x in [
                "embedding", "tts", "dall-e", "whisper", "image", "moderation", "transcribe", "audio", "search", "codex", "babbage", "davinci"
            ])
        allowed_ids = [m["id"] for m in available_models if is_relevant(m) and (m["id"] not in ADMIN_ONLY_MODELS or is_admin(user_id))]
        if model in allowed_ids:
            set_user_model(user_id, model)
            await query.answer(f"–ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∞ –Ω–∞ {model}")
            await model_command(update, context)
        else:
            await query.answer("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")

@admin_only
async def reloadmodels_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    res = await reload_models()
    if res:
        await update.message.reply_text("–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª—ë–Ω.", parse_mode=ParseMode.HTML)
    else:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π.", parse_mode=ParseMode.HTML)

@admin_only
async def admin_command_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await admin_command(update, context)

MAX_TOKENS_PER_USER = 20000

def get_tokens_stat(user_id):
    history = get_user_history(user_id)
    return sum(
        len(part.get("text", "")) if isinstance(msg["content"], list)
        else len(msg["content"])
        for msg in history
        for part in (msg["content"] if isinstance(msg["content"], list) else [msg["content"]])
    )

@allowed_only
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    user_id = user.id
    prompt = update.message.text

    # --- –ï—Å–ª–∏ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç ---
    if user_id in ACTIVE_FILE_SESSIONS:
        session = ACTIVE_FILE_SESSIONS[user_id]
        thread_id = session["thread_id"]
        assistant_id = session["assistant_id"]
        async with aiohttp.ClientSession() as session_http:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å –≤ thread
            url_msg = f"https://api.proxyapi.ru/openai/v1/threads/{thread_id}/messages"
            payload = {"role": "user", "content": prompt}
            headers = {
                "Authorization": f"Bearer {PROXYAPI_KEY}",
                "Content-Type": "application/json",
                "OpenAI-Beta": "assistants=v2"
            }
            async with session_http.post(url_msg, headers=headers, json=payload) as resp:
                msg_data = await resp.json()
                if "id" not in msg_data:
                    await update.message.reply_text("–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞ –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É.")
                    return
            run_id = await run_thread(session_http, assistant_id, thread_id)
            msg = await update.message.reply_text("‚úçÔ∏è –í–æ–ø—Ä–æ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω, –∂–¥—É –æ—Ç–≤–µ—Ç–∞...")
            status = await wait_run_complete(session_http, thread_id, run_id)
            if status != "completed":
                await msg.edit_text("‚ùóÔ∏èAI –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤–æ–≤—Ä–µ–º—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                return
            result = await get_thread_response(session_http, thread_id)
            if result and result.strip():
                safe_text = markdown_code_to_html(result)
                footer = "\n\n<i>–ß—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–±–æ—Ç—É —Å —ç—Ç–∏–º —Ñ–∞–π–ª–æ–º, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /closefile</i>"
                if len(safe_text) + len(footer) > 4000:
                    safe_text = safe_text[:4000 - len(footer)]
                safe_text += footer
                if len(safe_text) > 4000:
                    preview = safe_text[:4000]
                    await msg.edit_text(
                        preview + "\n\n<code>[–û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –≤–æ –≤–ª–æ–∂–µ–Ω–∏–∏]</code>",
                        parse_mode=ParseMode.HTML
                    )
                    filename = "full_result.txt"
                    with open(filename, "w", encoding="utf-8") as f:
                        f.write(result)
                    with open(filename, "rb") as f:
                        await update.message.reply_document(f, filename=filename, caption="–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç")
                    os.remove(filename)
                else:
                    await msg.edit_text(safe_text, parse_mode=ParseMode.HTML)
                add_to_history(user_id, "assistant", result)
            else:
                await msg.edit_text("‚ùóÔ∏èAI –Ω–µ —Å–º–æ–≥ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ –≤–∞—à–µ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É.")
        return

    # --- –û–±—ã—á–Ω—ã–π –¥–∏–∞–ª–æ–≥, –µ—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π file-—Å–µ—Å—Å–∏–∏ ---
    reply_ref = ""
    if update.message.reply_to_message:
        orig = update.message.reply_to_message
        reply_content = orig.text or orig.caption or "[–Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞]"
        if len(reply_content) > 500:
            reply_content = reply_content[:500] + "‚Ä¶"
        reply_ref = f'üí¨ –í –æ—Ç–≤–µ—Ç –Ω–∞:\n"{reply_content}"\n\n'

    full_prompt = reply_ref + prompt

    history = get_user_history(user_id)
    history.append({"role": "user", "content": full_prompt})
    add_to_history(user_id, "user", full_prompt)

    model = get_user_model(user_id)
    msg = await update.message.reply_text("‚úçÔ∏è –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")

    reply_text = ""
    last_sent = ""
    token_count = 0
    has_updated_once = False

    try:
        async for chunk in ask_llm_stream_history(history, model):
            if 'choices' in chunk and chunk['choices']:
                delta = chunk['choices'][0]['delta']
                content = delta.get('content', '')
                if content:
                    reply_text += content
                    token_count += 1
                    if (token_count % 8 == 0 or len(reply_text) - len(last_sent) > 30) or not has_updated_once:
                        try:
                            await msg.edit_text(reply_text + " ‚ñç")
                            last_sent = reply_text
                            has_updated_once = True
                        except Exception as e:
                            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ edit_text: {e}\n–û—Ç–≤–µ—Ç: {reply_text}")
        safe_text = markdown_code_to_html(reply_text)
        await msg.edit_text(safe_text, parse_mode=ParseMode.HTML)
        add_to_history(user_id, "assistant", reply_text)
        logger.info(f'[Text] –ì–æ—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {reply_text[:100]}...')
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ edit_text: {e}\n–û—Ç–≤–µ—Ç: {reply_text}")
        await msg.edit_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

@allowed_only
async def draw_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    user_id = user.id
    prompt = " ".join(context.args) if context.args else None

    if not prompt:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –ø–æ—Å–ª–µ /draw\n\n–ù–∞–ø—Ä–∏–º–µ—Ä:\n/draw –∫–æ—Ç —É—á—ë–Ω—ã–π –Ω–∞ –≤–µ–ª–æ—Å–∏–ø–µ–¥–µ –≤ —Å—Ç–∏–ª–µ –∫–æ–º–∏–∫—Å–∞")
        return

    msg = await update.message.reply_text("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

    try:
        url = "https://api.proxyapi.ru/openai/v1/images/generations"
        headers = {"Authorization": f"Bearer {PROXYAPI_KEY}", "Content-Type": "application/json"}
        payload = {
            "model": "dall-e-3",
            "prompt": prompt,
            "n": 1,
            "size": "1024x1024",
        }

        async with aiohttp.ClientSession() as session:
            async with session.post(url, headers=headers, json=payload, timeout=120) as resp:
                if resp.status != 200:
                    text = await resp.text()
                    logger.error(f"DALL-E –æ—à–∏–±–∫–∞: {resp.status} {text}")
                    await msg.edit_text(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {text}")
                    return
                result = await resp.json()

        image_url = result["data"][0]["url"]
        # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É
        await msg.delete()
        await update.message.reply_photo(photo=image_url, caption=f'–í–æ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é:\n<code>{prompt}</code>', parse_mode=ParseMode.HTML)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        await msg.edit_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

async def create_vector_store_and_upload_file(session, file_bytes, file_name):
    # 1. –°–æ–∑–¥–∞—Ç—å vector store
    url_vs = "https://api.proxyapi.ru/openai/v1/vector_stores"
    headers = {
        "Authorization": f"Bearer {PROXYAPI_KEY}",
        "Content-Type": "application/json",
        "OpenAI-Beta": "assistants=v2"
    }
    async with session.post(url_vs, headers=headers, json={}, timeout=30) as resp:
        vs_data = await resp.json()
    if "id" not in vs_data:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è vector store: {json.dumps(vs_data, ensure_ascii=False)}")
        raise Exception(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è vector store: {vs_data.get('error', vs_data)}")
    vector_store_id = vs_data["id"]

    # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª –≤ /files –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!
    url_files = "https://api.proxyapi.ru/openai/v1/files"
    headers_files = {
        "Authorization": f"Bearer {PROXYAPI_KEY}",
        "OpenAI-Beta": "assistants=v2"
    }
    # –ü–æ–ª—É—á–∞–µ–º mimetype (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
    mime = mimetypes.guess_type(file_name)[0] or 'application/octet-stream'
    data_files = aiohttp.FormData()
    data_files.add_field(
        'file',
        BytesIO(file_bytes),            # –í–ê–ñ–ù–û!
        filename=file_name,
        content_type=mime
    )
    data_files.add_field('purpose', 'assistants')
    async with session.post(url_files, headers=headers_files, data=data_files, timeout=120) as resp:
        file_obj = await resp.json()
    if "id" not in file_obj:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {json.dumps(file_obj, ensure_ascii=False)}")
        raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {file_obj.get('error', file_obj)}")
    file_id = file_obj["id"]

    # 3. –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º file_id –∫ vector_store
    url_vs_files = f"https://api.proxyapi.ru/openai/v1/vector_stores/{vector_store_id}/files"
    headers_vs_files = {
        "Authorization": f"Bearer {PROXYAPI_KEY}",
        "Content-Type": "application/json",
        "OpenAI-Beta": "assistants=v2"
    }
    payload_vs_files = {"file_id": file_id}
    async with session.post(url_vs_files, headers=headers_vs_files, json=payload_vs_files, timeout=30) as resp:
        vs_file_obj = await resp.json()
    if "id" not in vs_file_obj:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–≤—è–∑–∫–∏ —Ñ–∞–π–ª–∞ –∫ vector store: {json.dumps(vs_file_obj, ensure_ascii=False)}")
        raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–≤—è–∑–∫–∏ —Ñ–∞–π–ª–∞ –∫ vector store: {vs_file_obj.get('error', vs_file_obj)}")

    return vector_store_id, file_id

async def create_assistant(session, vector_store_id, model="gpt-4o", instructions=None):
    url = "https://api.proxyapi.ru/openai/v1/assistants"
    payload = {
        "model": model,
        "instructions": instructions or "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ø–æ–º–æ–≥–∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –ø—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É.",
        "tools": [{"type": "file_search"}],
        "tool_resources": {
            "file_search": {
                "vector_store_ids": [vector_store_id]
            }
        }
    }
    headers = {
        "Authorization": f"Bearer {PROXYAPI_KEY}",
        "Content-Type": "application/json",
        "OpenAI-Beta": "assistants=v2"
    }
    async with session.post(url, headers=headers, json=payload, timeout=30) as resp:
        data = await resp.json()
    if "id" not in data:
        logger.error(f"[ProxyAPI] –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {json.dumps(data, ensure_ascii=False)}")
        raise Exception(f"–û—à–∏–±–∫–∞ ProxyAPI (assistant): {data.get('error', data)}")
    return data["id"]

async def create_thread(session, user_message):
    url = "https://api.proxyapi.ru/openai/v1/threads"
    message = {
        "role": "user",
        "content": user_message,
    }
    payload = {
        "messages": [message]
    }
    headers = {
        "Authorization": f"Bearer {PROXYAPI_KEY}",
        "Content-Type": "application/json",
        "OpenAI-Beta": "assistants=v2"
    }
    async with session.post(url, headers=headers, json=payload, timeout=30) as resp:
        data = await resp.json()
    if "id" not in data:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ thread: {json.dumps(data, ensure_ascii=False)}")
        raise Exception(f"–û—à–∏–±–∫–∞ ProxyAPI (thread): {data.get('error', data)}")
    return data["id"]

async def run_thread(session, assistant_id, thread_id):
    url = f"https://api.proxyapi.ru/openai/v1/threads/{thread_id}/runs"
    payload = {"assistant_id": assistant_id}
    headers = {
        "Authorization": f"Bearer {PROXYAPI_KEY}",
        "Content-Type": "application/json",
        "OpenAI-Beta": "assistants=v2"
    }
    async with session.post(url, headers=headers, json=payload, timeout=30) as resp:
        data = await resp.json()
    if "id" not in data:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ run: {json.dumps(data, ensure_ascii=False)}")
        raise Exception(f"–û—à–∏–±–∫–∞ ProxyAPI (run): {data.get('error', data)}")
    return data["id"]

async def wait_run_complete(session, thread_id, run_id, timeout=90):
    url = f"https://api.proxyapi.ru/openai/v1/threads/{thread_id}/runs/{run_id}"
    headers = {
        "Authorization": f"Bearer {PROXYAPI_KEY}",
        "OpenAI-Beta": "assistants=v2"
    }
    import asyncio
    for _ in range(timeout // 2):
        async with session.get(url, headers=headers, timeout=10) as resp:
            data = await resp.json()
            if "status" not in data:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è run: {json.dumps(data, ensure_ascii=False)}")
                raise Exception(f"–û—à–∏–±–∫–∞ ProxyAPI (run status): {data.get('error', data)}")
            if data.get("status") in ("completed", "failed", "cancelled", "expired"):
                return data.get("status")
        await asyncio.sleep(2)
    logger.error("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è run")
    return "timeout"

async def get_thread_response(session, thread_id):
    url = f"https://api.proxyapi.ru/openai/v1/threads/{thread_id}/messages"
    headers = {
        "Authorization": f"Bearer {PROXYAPI_KEY}",
        "OpenAI-Beta": "assistants=v2"
    }
    async with session.get(url, headers=headers, timeout=30) as resp:
        data = await resp.json()
    if "data" not in data:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π thread: {json.dumps(data, ensure_ascii=False)}")
        raise Exception(f"–û—à–∏–±–∫–∞ ProxyAPI (get messages): {data.get('error', data)}")
    msgs = data.get("data", [])
    for msg in reversed(msgs):
        if msg.get("role") == "assistant":
            parts = msg.get("content", [])
            for part in parts:
                if part["type"] == "text":
                    return part["text"]["value"]
    logger.warning("–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö thread")
    return None

@allowed_only
async def closefile_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if user_id in ACTIVE_FILE_SESSIONS:
        ACTIVE_FILE_SESSIONS.pop(user_id, None)
        await update.message.reply_text(
            "–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–∫—Ä—ã—Ç. –¢–µ–ø–µ—Ä—å –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã –±–æ–ª—å—à–µ –Ω–µ –±—É–¥—É—Ç —Å–≤—è–∑–∞–Ω—ã —Å —Ñ–∞–π–ª–æ–º."
        )
    else:
        await update.message.reply_text(
            "–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è."
        )

def xlsx_to_txt_bytes(file_bytes, file_name="file.xlsx", max_rows=50):
    excel_io = BytesIO(file_bytes)
    df = pd.read_excel(excel_io, engine='openpyxl')
    # –û–±—Ä–µ–∑–∞–µ–º –ø–æ –º–∞–∫—Å–∏–º—É–º—É —Å—Ç—Ä–æ–∫ (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–ø–æ–ª–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç)
    df = df.head(max_rows)
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∫ —Ç–∞–±–ª–∏—Ü—É (—Ç–∞–±–∞–º–∏ –∏–ª–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏)
    txt = df.to_string(index=False)
    return txt.encode('utf-8')

SUPPORTED_EXTS = {
    ".pdf", ".txt", ".csv", ".doc", ".docx", ".ppt", ".pptx",
    ".epub", ".html", ".htm", ".md", ".json", ".rtf"
}

import os
import pandas as pd
from io import BytesIO

SUPPORTED_EXTS = {
    ".pdf", ".txt", ".doc", ".docx", ".ppt", ".pptx",
    ".epub", ".html", ".htm", ".md", ".json", ".rtf"
}

MAX_TELEGRAM_MSG_LEN = 4000  # —á—É—Ç—å –º–µ–Ω—å—à–µ –ª–∏–º–∏—Ç–∞

def xlsx_to_txt_bytes(file_bytes, file_name="file.xlsx", max_rows=2000):
    excel_io = BytesIO(file_bytes)
    df = pd.read_excel(excel_io, engine='openpyxl')
    df = df.head(max_rows)
    txt = df.to_string(index=False)
    return txt.encode('utf-8')

@allowed_only
async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    import traceback

    user = update.effective_user
    user_id = user.id
    document = update.message.document
    file_name = document.file_name
    file_id = document.file_id
    ext = os.path.splitext(file_name)[-1].lower()

    tg_file = await context.bot.get_file(file_id)
    file_bytes = await tg_file.download_as_bytearray()

    if ext == ".xlsx":
        try:
            file_bytes = xlsx_to_txt_bytes(file_bytes, file_name, max_rows=3000)
            file_name = file_name.rsplit(".", 1)[0] + ".txt"
            ext = ".txt"
        except Exception as e:
            await update.message.reply_text(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å Excel –≤ TXT: {e}")
            return

    if ext not in SUPPORTED_EXTS:
        await update.message.reply_text(
            f"–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ <b>{ext}</b> –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É. "
            "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç—ã: PDF, DOCX, TXT, PPTX, EPUB, HTML, MD, JSON, RTF.",
            parse_mode=ParseMode.HTML
        )
        return

    if document.file_size > 40 * 1024 * 1024:  # —É–≤–µ–ª–∏—á–∏–ª –ª–∏–º–∏—Ç –¥–æ 40 –ú–ë
        await update.message.reply_text("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å–∏–º—É–º 40 –ú–ë –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤).")
        return

    msg = await update.message.reply_text(f"üìÑ –ó–∞–≥—Ä—É–∂–∞—é –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–æ–∫—É–º–µ–Ω—Ç {file_name}...")

    try:
        async with aiohttp.ClientSession() as session:
            vector_store_id, _ = await create_vector_store_and_upload_file(session, file_bytes, file_name)
            assistant_id = await create_assistant(session, vector_store_id)
            question = update.message.caption.strip() if update.message.caption else "–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω."
            thread_id = await create_thread(session, question)
            ACTIVE_FILE_SESSIONS[user.id] = {
                "vector_store_id": vector_store_id,
                "assistant_id": assistant_id,
                "thread_id": thread_id,
                "file_id": file_id,
                "file_name": file_name,
            }
            if update.message.caption and update.message.caption.strip():
                # –ë—ã–ª –≤–æ–ø—Ä–æ—Å ‚Äî —Å—Ä–∞–∑—É –æ—Ç–≤–µ—á–∞–µ–º
                run_id = await run_thread(session, assistant_id, thread_id)
                await msg.edit_text("‚úçÔ∏è –í–æ–ø—Ä–æ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω, –∂–¥—É –æ—Ç–≤–µ—Ç–∞...")
                status = await wait_run_complete(session, thread_id, run_id)
                if status != "completed":
                    await msg.edit_text("‚ùóÔ∏èAI –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤–æ–≤—Ä–µ–º—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                    return
                result = await get_thread_response(session, thread_id)
                if result and result.strip():
                    safe_text = markdown_code_to_html(result)
                    footer = "\n\n<i>–ß—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–±–æ—Ç—É —Å —ç—Ç–∏–º —Ñ–∞–π–ª–æ–º, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /closefile</i>"
                    if len(safe_text) + len(footer) > 4000:
                        safe_text = safe_text[:4000 - len(footer)]
                    safe_text += footer
                    await msg.edit_text(safe_text, parse_mode=ParseMode.HTML)
                    add_to_history(user_id, "assistant", result)
                else:
                    await msg.edit_text("‚ùóÔ∏èAI –Ω–µ —Å–º–æ–≥ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ –≤–∞—à–µ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É.")
            else:
                await msg.edit_text(
                    "–î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω. –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –∫ –Ω–µ–º—É –≤–æ–ø—Ä–æ—Å—ã –æ–±—ã—á–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏.\n"
                    "–ß—Ç–æ–±—ã –∑–∞–∫—Ä—ã—Ç—å —Ñ–∞–π–ª ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /closefile"
                )
            logger.info(f'[Document/AssistantsAPI] –î–æ–∫—É–º–µ–Ω—Ç {file_name} –¥–ª—è {user.id} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.')
    except Exception as e:
        tb = traceback.format_exc()
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–º (AssistantsAPI): {e!r}\n{tb}")
        await msg.edit_text(
            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ü–æ–¥—Ä–æ–±–Ω–µ–µ:\n<pre>{e!r}</pre>\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            parse_mode=ParseMode.HTML
        )

async def dochelp_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (
        "üìÑ –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ PDF, DOCX, TXT –∏–ª–∏ –¥—Ä—É–≥–æ–π –¥–æ–∫—É–º–µ–Ω—Ç –≤ —ç—Ç–æ—Ç —á–∞—Ç!\n"
        "–ú–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–ø–∏—Å—å ‚Äî —ç—Ç–æ –±—É–¥–µ—Ç –≤–∞—à –≤–æ–ø—Ä–æ—Å –∫ —Ñ–∞–π–ª—É.\n"
        "–ù–∞–ø—Ä–∏–º–µ—Ä:\n"
        "‚Äî \"–ù–∞–π–¥–∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–∑–∏—Å—ã\"\n"
        "‚Äî \"–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ\"\n"
        "‚Äî \"–ï—Å—Ç—å –ª–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ –ú–æ—Å–∫–≤–∞?\"\n"
        "–ë–æ—Ç –∑–∞–≥—Ä—É–∑–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –æ—Ç–≤–µ—Ç–∏—Ç."
    )
    await update.message.reply_text(text)

def main():
    logger.info("–ó–∞–ø—É—Å–∫ Telegram –±–æ—Ç–∞")
    loop = asyncio.get_event_loop()
    loop.run_until_complete(reload_models())
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("menu", menu_command))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("admin", admin_command_handler))
    app.add_handler(CommandHandler("model", model_command))
    app.add_handler(CommandHandler("reloadmodels", reloadmodels_command))
    app.add_handler(CommandHandler("reset", reset_command))
    app.add_handler(CommandHandler("export", export_command))
    app.add_handler(CommandHandler("broadcast", broadcast_command))
    app.add_handler(CommandHandler("cancel", cancel_command))
    app.add_handler(CommandHandler("draw", draw_command))
    app.add_handler(CommandHandler("dochelp", dochelp_command))
    app.add_handler(CommandHandler("closefile", closefile_command))
    app.add_handler(CallbackQueryHandler(model_callback, pattern="set_model:"))
    app.add_handler(CallbackQueryHandler(admin_callback, pattern="admin:"))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, broadcast_text_handler), group=0)
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message), group=1)
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    app.add_error_handler(error_handler)
    app.post_init = set_bot_commands
    app.run_polling()

if __name__ == '__main__':
    main()
